---
id: T-010-11
story: S-010
title: scenario-cli-entry-point
type: task
status: open
priority: high
phase: done
depends_on: [T-010-08, T-010-10]
---

## Context

Build the CLI entry point for running scenarios from the command line. This is the developer's
primary interface for executing test scenarios, comparing results, and validating changes.

See `docs/specs/scenario-testing-system.md` §6.2 for the CLI design.

### CLI

```bash
# Run one scenario
uv run python -m speednik.scenarios.cli scenarios/hillside_complete.yaml

# Run all scenarios
uv run python -m speednik.scenarios.cli --all

# Override agent for all scenarios
uv run python -m speednik.scenarios.cli --all --agent hold_right

# Save results
uv run python -m speednik.scenarios.cli --all -o results/run_001.json
```

### Implementation

```python
# speednik/scenarios/cli.py

def main():
    parser = argparse.ArgumentParser(description="Run Speednik scenarios")
    parser.add_argument("scenarios", nargs="*", help="Scenario YAML files or glob")
    parser.add_argument("--all", action="store_true", help="Run all in scenarios/")
    parser.add_argument("--agent", help="Override agent for all scenarios")
    parser.add_argument("--output", "-o", help="Output dir for results JSON")
    parser.add_argument("--trajectory", action="store_true", help="Include trajectory")
    parser.add_argument("--compare", help="Compare against baseline JSON")
    args = parser.parse_args()

    scenarios = load_scenarios(args.scenarios, run_all=args.all)
    results = []

    for scenario_def in scenarios:
        if args.agent:
            scenario_def.agent = args.agent
        outcome = run_scenario(scenario_def)
        results.append(outcome)
        print_outcome(outcome)

    if args.output:
        save_results(results, args.output, include_trajectory=args.trajectory)
    if args.compare:
        compare_results(results, args.compare)
```

### Console output

`print_outcome` should produce clear, scannable output:

```
✓ hillside_complete     PASS  1847 frames  42.3ms  max_x=3200.5
✗ hillside_hold_right   FAIL  3600 frames  98.1ms  max_x=1456.2  stuck_at=1456.2
✓ pipeworks_jump        PASS  2103 frames  61.7ms  max_x=2800.0
```

Use color if stdout is a TTY (green for pass, red for fail). Plain text otherwise.

### Exit code

Exit 0 if all scenarios pass, exit 1 if any fail. This makes the CLI usable in CI pipelines:

```bash
uv run python -m speednik.scenarios.cli --all || echo "Scenarios failed!"
```

### __main__ entry

Also add `speednik/scenarios/__main__.py` so `python -m speednik.scenarios` works as an
alias for `python -m speednik.scenarios.cli`.

### Location

- `speednik/scenarios/cli.py` — main CLI logic
- `speednik/scenarios/__main__.py` — entry point
- `speednik/scenarios/output.py` — print_outcome, save_results (JSON serialization)

## Acceptance Criteria

- [ ] `uv run python -m speednik.scenarios.cli scenarios/hillside_complete.yaml` runs
- [ ] `--all` flag discovers and runs all scenarios in `scenarios/`
- [ ] `--agent` flag overrides agent for all scenarios
- [ ] `-o` flag saves results as JSON
- [ ] `--trajectory` flag includes per-frame data in JSON output
- [ ] `--compare` flag loads baseline and prints comparison (placeholder — full
  implementation in T-010-13)
- [ ] Console output shows pass/fail, frames, wall time, key metrics per scenario
- [ ] Exit code 0 on all-pass, 1 on any failure
- [ ] `python -m speednik.scenarios` works as alias
- [ ] No Pyxel imports
- [ ] `uv run pytest tests/ -x` passes
