---
id: T-010-14
story: S-010
title: cleanrl-ppo-fork
type: task
status: open
priority: high
phase: done
depends_on: [T-010-13]
---

## Context

Fork CleanRL's `ppo.py` into the project and configure it for Speednik environments. This
is Layer 6 — the RL training entry point. The fork requires exactly two changes to the
CleanRL source.

See `docs/specs/scenario-testing-system.md` §8.1–8.3 for the integration design.

### Why CleanRL

CleanRL provides single-file RL implementations with no framework abstraction. `ppo.py` is
~300 lines, uses PyTorch directly, supports W&B logging, and is the standard reference for
PPO. Forking a single file is simpler and more maintainable than depending on CleanRL as a
library.

### Fork changes

**Change 1**: Add registration import.

```python
import speednik.env_registration  # triggers gym.register() calls
```

**Change 2**: Change default env_id.

```python
env_id: str = "speednik/Hillside-v0"
```

That's it. CleanRL's PPO uses `Discrete` action space with `Categorical` distribution and
`Box` observation space with MLP actor/critic — both match our env exactly.

### Wrapper stack

In the forked `make_env`:

```python
def make_env(env_id, idx, capture_video, run_name):
    def thunk():
        env = gym.make(env_id)
        env = gym.wrappers.RecordEpisodeStatistics(env)
        env = gym.wrappers.NormalizeObservation(env)
        env = gym.wrappers.TransformObservation(
            env, lambda obs: np.clip(obs, -10, 10),
            observation_space=env.observation_space
        )
        env = gym.wrappers.NormalizeReward(env, gamma=0.99)
        env = gym.wrappers.TransformReward(env, lambda r: np.clip(r, -10, 10))
        return env
    return thunk
```

### Dependencies

Add to the project:
- `torch` (PyTorch)
- `cleanrl` is NOT a dependency — we fork the file
- `wandb` (optional, for `--track` flag)
- `tensorboard` (optional, for local logging)

These are training-only dependencies. Consider putting them in an optional dependency group:
`uv add --group train torch wandb tensorboard`.

### Smoke test

Run a very short training (~10K timesteps, ~2 minutes):

```bash
uv run python tools/ppo_speednik.py \
    --env-id speednik/Hillside-v0 \
    --total-timesteps 10000 \
    --num-envs 4 \
    --num-steps 128
```

Verify: no crashes, loss values are finite, model checkpoint saves, episode statistics
are logged.

### Location

- `tools/ppo_speednik.py` — forked CleanRL ppo.py
- `pyproject.toml` — add torch/wandb/tensorboard to optional train group

## Acceptance Criteria

- [ ] `tools/ppo_speednik.py` is a working fork of CleanRL's `ppo.py`
- [ ] Only 2 changes from upstream: registration import + default env_id
- [ ] Wrapper stack includes NormalizeObservation, NormalizeReward, clip transforms
- [ ] `torch` added as optional dependency (train group)
- [ ] 10K timestep smoke test completes without crashes
- [ ] Loss values are finite throughout training
- [ ] Model checkpoint saves to disk
- [ ] Episode statistics logged (episodic_return, episodic_length)
- [ ] `--track` flag works with W&B (if wandb installed)
- [ ] `--env-id speednik/Pipeworks-v0` also works
- [ ] No Pyxel imports in the training script
- [ ] `uv run pytest tests/ -x` passes (training deps are optional, tests don't require them)
